---
title: Causal Inference and Discovery in Python - Part 1
author: Bruno Lee. J.
date: 2024-04-22 16:10:00 +0900
categories: [Book, Causal Inference]
tags: [causal inference, python]
pin: true
math: true
mermaid: true
---

## Causality - an Introduction
이번 장에서는 Observational, Interventional, Counterfactual Queries와 분포 (distribution)의 차이점에 대해서 공부한다. 그리고 Linear Regression, Graph, Causal model간의 연관성을 살펴봅니다. 또한 마지막으로, 거의 모든 인과 관계 연구에서 필수적인 역할을 하는 그래픽 구조의 중요한 특성에 대해 알아본다.

파트 구성은 아래와 같다.
1. **Causality - Hey, We Have Machine Learning, So Why Even Bother?**
2. **Judea Pearl and Ladder of Causation**
3. **Regression, Observations, and Interventions**
4. **Graphical Models**
5. **Forks, Chains, and Immoralities**

### Causality - Hey, We Have Machine Learning, So Why Even Bother?
처음은 이러한 질문으로 시작된다.

> "인과관계란 무엇일까? 인과 간례 추론은 통계적 추론과 다른가? 그렇다면 어떻게 다를까? 머신 러닝이 충분히 좋은 것 같다면 인과관계가 꼭 필요할까?"

지난 5 ~ 10년 동안 빠르게 변화하는 머신 러닝 환경을 지켜봤다면, Computer Vision, NLP 및 기타 분야에서 최신 머신 러닝 알고리즘의 <u>unresonable effectiveness</u>에 대한 사례를 봤을 것이다. (머신러닝에서는 자주 쓰이는 용어인가보다.)

![cibook3](https://github.com/brunoleej/brunoleej.github.io/blob/master/assets/img/cibook/cibook3.png?raw=true)

![cibook2](https://github.com/brunoleej/brunoleej.github.io/blob/master/assets/img/cibook/cibook2.jpeg?raw=true)

DALL-E 2나 GPT-3/4와 같은 알고리즘은 연구 커뮤니티 뿐만 아니라 일반 대중의 인식에도 많은 영향을 끼쳤다.

![cibook4](https://github.com/brunoleej/brunoleej.github.io/blob/master/assets/img/cibook/cibook4.png?raw=true)

그런데 이 모든것들이 그렇게 잘 작동한다면 왜 굳이 다른 시도들을 하는지 물어볼 수 있다. 그래서 이 장에서는 인과 관계의 역사에 대한 논의와 순수 통계적 접근 방식이 아닌 인과적 접근 방식을 모델링에 사용하는 몇가지 동기를 살표보고 confounding에 대한 개념을 소개한다.


### A breif history of causality (원인과 결과의 관계: 아리스토텔레스부터 흄까지)

원인과 결과의 관계는 인류 역사와 함께 발전해온 개념이다. 고대 그리스 철학자인 아리스토텔레스는 모든 지식의 기본 요소로 원인에 대한 이해를 강조해왔다. (궁금한 사람은 아리스토텔레스의 4원인론에 대해서 검색해보면 된다.) 그는 원인을 4가지 유형 (재료적 원인, 형식적 원인, 효과적 원인, 목적적 원인)으로 구분했는데, 이는 때때로 현대에서는 직관적이지 않을 수도 있다.

![cibook5](https://github.com/brunoleej/brunoleej.github.io/blob/master/assets/img/cibook/cibook5.png?raw=true)

18세기 스코틀랜드의 철학자인 데이비드 흄은 원인과 결과에 대한 더 통합된 틀을 제안했는데, 흄은 우리가 원인과 결과의 관계를 직접적으로 관찰하는 것이 아니라, 단지 사건들이 연속적으로 일어나는 것을 경험한다고 주장했다. 
ex) 한 당구공이 다른 공을 치고 움직이면, 우리는 그 움직임을 감지할 수 있지만, 그 사이의 "필연적 연결"이나 "힘"을 느낄 수는 없다.

흄의 원인과 결과에 대한 이론은 두가지 관점에서 흥미롭다. 
1. 이 이론은 심리학에서 "**조건화**"라고 하는 강력한 학습 이론과 유사하다. 조건화는 사건이나 객체를 행동이나 반응과 연결짓는 학습 형태이다. 이는 인간뿐만 아니라 개, 고양이, 심지어 달팽이와 같은 단순한 생물에서도 관찰된다.

2. 대부분의 고전적인 머신러닝 알고리즘도 연관성을 기반으로 작동한다. 우리가 지도 학습을 통해 신경망을 훈련시킬 때, 입력과 출력을 연결하는 함수를 찾으려고 한다. 이 과정에서 어떤 입력 요소가 출력을 예측하는데 유용한지 파악하는 것이 중요하며, 대부분의 경우, 연관성이 이 목적을 충분히 달성해준다.

이처럼 원인과 결과의 개념은 고대 철학에서 현대의 심리학 및 인공지능 기술에 이르기까지 다양한 분야에서 중요한 역할을 하고 있다. 우리가 경험하는 세상을 이해하는데 이러한 이론들이 어떻게 적용되는지 알아보는 것은 매우 흥미로운 일이 아닐 수가 없다.


### Why causality? Ask babies!
흄의 인과론에서 빠진 것이 있을까? 다른 많은 철학자들이 이 질문에 답하려고 했지만, 오늘은 특히 흥미로운 대답 중 하나인 아기에게서 나온 대답에 초점을 맞춰보겠다.

- Interacting with the world

    앨리슨 고프닉은 미국의 아동 심리학자로, 영아가 어떻게 세계에 대한 모델을 발달시키는지 연구했다. 그녀는 컴퓨터 과학자들과 협력하여 인간 아기가 외부 세계에 대한 상식적 개념을 어떻게 구축하는지 이해를 돕고 있다. 특히, <u>아이들은 어른들보다 훨씬 더 연관성 학습을 사용하지만, 동시에 그들은 끝없는 실험가다.</u>

    아이가 장난감을 던지는 것을 그만두게 하려는 부모를 본적이 있는가? 일부 부모는 이런 행동을 무례하거나 파괴적으로 생각할 수 있다. 하지만 아기들은 다른 동기를 가지고 있다. 그들은 물리 법칙과 사회적 상호작용의 규칙을 배울 수 있도록 체계적인 실험을 진행한다. 심지어 11개월 된 유아조차도 예측 가능한 객체보다 예측 불가능한 특성 (ex. 벽을 통과하는)을 가진 객체로 실험을 선호하는 경향이 있다. 이러한 선호는 그들이 세계 모델을 효율적으로 구축할 수 있게 한다.

    우리가 아기들로부터 배울 수 있는 것은, 흄이 제안한 것처럼 단순히 세계를 관찰하는 것에 국한되지 않는다는 것이다. 우리는 또한 그와 상호작용을 할 수 있다. 인과 추론 맥락에서, 이러한 상호작용을 "<u>**Intervention**</u>" 또는 "<u>**개입**</u>"이라고 부른다. 이 개입은 많은 사람들이 과학적 방법의 성배로 여기는 <u>**Randomized Cotnrolled Trial (RCT)**</u>의 핵심인 것이다.

